---
layout: post
title: "Effective Altruism"
excerpt: EA
tags:
 -
---
* prioritization of how we can maximize impact to help current + future humans.
* [80000 Hours]({% bidi 80000 hours %}) has some surprising research and a [quiz ](https://www.guidedtrack.com/programs/3025/embed/auth?source=https%3A%2F%2F80000hours.org%2Fproblem-quiz%2F) here. It turns out that my current work in [[security]] is likely maximally impactful, since it allows me to help protect the development of [ai]({% bidi ai %}). 
* list of [problem profiles](https://80000hours.org/problem-profiles/), which takes many problems and ranks them.
    - helping create safe AI
        - global priorities research
* working against global warming was surprisingly really far down the list

